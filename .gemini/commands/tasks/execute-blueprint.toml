[metadata]
argument-hint = "{{plan_id}}"
description = "Execute the task in the plan"

[prompt]
content = """# Task Execution\n\n## Assistant Configuration\n\nBefore proceeding with this command, you MUST load and respect the assistant's configuration:\n\n**Run the following scripts:**\n```bash\nASSISTANT=$(node .ai/task-manager/config/scripts/detect-assistant.cjs)\nnode .ai/task-manager/config/scripts/read-assistant-config.cjs \"$ASSISTANT\"\n```\n\nThe output above contains your global and project-level configuration rules. You MUST keep these rules and guidelines in mind during all subsequent operations in this command.\n\n---\n\nYou are the coordinator responsible for executing all tasks defined in the execution blueprint of a plan document, so choose an appropriate sub-agent for this role. Your role is to coordinate phase-by-phase execution, manage parallel task processing, and ensure validation gates pass before phase transitions.\n\n## Critical Rules\n\n1. **Never skip validation gates** - Phase progression requires successful validation\n2. **Maintain task isolation** - Parallel tasks must not interfere with each other\n3. **Preserve dependency order** - Never execute a task before its dependencies\n4. **Document everything** - All decisions, issues, and outcomes must be recorded in the \"Execution Summary\", under \"Noteworthy Events\"\n5. **Fail safely** - Better to halt and request help than corrupt the execution state\n\n## Input Requirements\n- A plan document with an execution blueprint section. See /TASK_MANAGER.md fo find the plan with ID {{plan_id}}\n- Task files with frontmatter metadata (id, group, dependencies, status)\n- Validation gates document: `/config/hooks/POST_PHASE.md`\n\n### Input Error Handling\n\nIf the plan does not exist, stop immediately and show an error to the user.\n\n**Note**: If tasks or the execution blueprint section are missing, they will be automatically generated before execution begins (see Task and Blueprint Validation below).\n\n### Task and Blueprint Validation\n\nBefore proceeding with execution, validate that tasks exist and the execution blueprint has been generated. If either is missing, automatically invoke task generation.\n\n**Validation Steps:**\n\n```bash\n# Extract validation results directly from script\nPLAN_FILE=$(node .ai/task-manager/config/scripts/validate-plan-blueprint.cjs {{plan_id}} planFile)\nPLAN_DIR=$(node .ai/task-manager/config/scripts/validate-plan-blueprint.cjs {{plan_id}} planDir)\nTASK_COUNT=$(node .ai/task-manager/config/scripts/validate-plan-blueprint.cjs {{plan_id}} taskCount)\nBLUEPRINT_EXISTS=$(node .ai/task-manager/config/scripts/validate-plan-blueprint.cjs {{plan_id}} blueprintExists)\n```\n\n4. **Automatic task generation**:\n\nIf either `$TASK_COUNT` is 0 or `$BLUEPRINT_EXISTS` is \"no\":\n   - Display notification to user: \"⚠️ Tasks or execution blueprint not found. Generating tasks automatically...\"\n   - Execute the following task generation process inline:\n\n   ## Embedded Task Generation\n\n   Think harder and use tools.\n\n   You are a comprehensive task planning assistant. Your role is to create detailed, actionable plans based on user input while ensuring you have all necessary context before proceeding.\n\n   Include /TASK_MANAGER.md for the directory structure of tasks.\n\n   ## Instructions\n\n   You will think hard to analyze the provided plan document and decompose it into atomic, actionable tasks with clear dependencies and groupings.\n\n   Use your internal Todo task tool to track the following process:\n\n   - [ ] Read and process plan {{plan_id}}\n   - [ ] Use the Task Generation Process to create tasks according to the Task Creation Guidelines\n   - [ ] Read and run the .ai/task-manager/config/hooks/POST_TASK_GENERATION_ALL.md\n\n   ### Input\n   - A plan document. See .ai/task-manager/config/TASK_MANAGER.md fo find the plan with ID {{plan_id}}\n   - The plan contains high-level objectives and implementation steps\n\n   ### Input Error Handling\n   If the plan does not exist. Stop immediately and show an error to the user.\n\n   ### Task Creation Guidelines\n\n   #### Task Minimization Principles\n   **Core Constraint:** Create only the minimum number of tasks necessary to satisfy the plan requirements. Target a 20-30% reduction from comprehensive task lists by questioning the necessity of each component.\n\n   **Minimization Rules:**\n   - **Direct Implementation Only**: Create tasks for explicitly stated requirements, not \"nice-to-have\" features\n   - **DRY Task Principle**: Each task should have a unique, non-overlapping purpose\n   - **Question Everything**: For each task, ask \"Is this absolutely necessary to meet the plan objectives?\"\n   - **Avoid Gold-plating**: Resist the urge to add comprehensive features not explicitly required\n\n   **Antipatterns to Avoid:**\n   - Creating separate tasks for \"error handling\" when it can be included in the main implementation\n   - Breaking simple operations into multiple tasks (e.g., separate \"validate input\" and \"process input\" tasks)\n   - Adding tasks for \"future extensibility\" or \"best practices\" not mentioned in the plan\n   - Creating comprehensive test suites for trivial functionality\n\n   #### Task Granularity\n   Each task must be:\n   - **Single-purpose**: One clear deliverable or outcome\n   - **Atomic**: Cannot be meaningfully split further\n   - **Skill-specific**: Executable by a single skill agent (examples below)\n   - **Verifiable**: Has clear completion criteria\n\n   #### Skill Selection and Technical Requirements\n\n   **Core Principle**: Each task should require 1-2 specific technical skills that can be handled by specialized agents. Skills should be automatically inferred from the task's technical requirements and objectives.\n\n   **Skill Selection Criteria**:\n   1. **Technical Specificity**: Choose skills that directly match the technical work required\n   2. **Agent Specialization**: Select skills that allow a single skilled agent to complete the task\n   3. **Minimal Overlap**: Avoid combining unrelated skill domains in a single task\n   4. **Creative Inference**: Derive skills from task objectives and implementation context\n\n   **Inspirational Skill Examples** (use kebab-case format):\n   - Frontend: `react-components`, `css`, `js`, `vue-components`, `html`\n   - Backend: `api-endpoints`, `database`, `authentication`, `server-config`\n   - Testing: `jest`, `playwright`, `unit-testing`, `e2e-testing`\n   - DevOps: `docker`, `github-actions`, `deployment`, `ci-cd`\n   - Languages: `typescript`, `python`, `php`, `bash`, `sql`\n   - Frameworks: `nextjs`, `express`, `drupal-backend`, `wordpress-plugins`\n\n   **Automatic Skill Inference Examples**:\n   - \"Create user login form\" → `[\"react-components\", \"authentication\"]`\n   - \"Build REST API for orders\" → `[\"api-endpoints\", \"database\"]`\n   - \"Add Docker deployment\" → `[\"docker\", \"deployment\"]`\n   - \"Write Jest tests for utils\" → `[\"jest\"]`\n\n   **Assignment Guidelines**:\n   - **1 skill**: Focused, single-domain tasks\n   - **2 skills**: Tasks requiring complementary domains\n   - **Split if 3+**: Indicates task should be broken down\n\n   ```\n   # Examples\n   skills: [\"css\"]  # Pure styling\n   skills: [\"api-endpoints\", \"database\"]  # API with persistence\n   skills: [\"react-components\", \"jest\"]  # Implementation + testing\n   ```\n\n   #### Meaningful Test Strategy Guidelines\n\n   **IMPORTANT** Make sure to copy this _Meaningful Test Strategy Guidelines_ section into all the tasks focused on testing, and **also** keep them in mind when generating tasks.\n\n   Your critical mantra for test generation is: \"write a few tests, mostly integration\".\n\n   **Definition of \"Meaningful Tests\":**\n   Tests that verify custom business logic, critical paths, and edge cases specific to the application. Focus on testing YOUR code, not the framework or library functionality.\n\n   **When TO Write Tests:**\n   - Custom business logic and algorithms\n   - Critical user workflows and data transformations\n   - Edge cases and error conditions for core functionality\n   - Integration points between different system components\n   - Complex validation logic or calculations\n\n   **When NOT to Write Tests:**\n   - Third-party library functionality (already tested upstream)\n   - Framework features (React hooks, Express middleware, etc.)\n   - Simple CRUD operations without custom logic\n   - Getter/setter methods or basic property access\n   - Configuration files or static data\n   - Obvious functionality that would break immediately if incorrect\n\n   **Test Task Creation Rules:**\n   - Combine related test scenarios into single tasks (e.g., \"Test user authentication flow\" not separate tasks for login, logout, validation)\n   - Focus on integration and critical path testing over unit test coverage\n   - Avoid creating separate tasks for testing each CRUD operation individually\n   - Question whether simple functions need dedicated test tasks\n\n   ### Task Generation Process\n\n   #### Step 1: Task Decomposition\n   1. Read through the entire plan\n   2. Identify all concrete deliverables **explicitly stated** in the plan\n   3. Apply minimization principles: question necessity of each potential task\n   4. Break each deliverable into atomic tasks (only if genuinely needed)\n   5. Ensure no task requires multiple skill sets\n   6. Verify each task has clear inputs and outputs\n   7. **Minimize test tasks**: Combine related testing scenarios, avoid testing framework functionality\n   8. Be very detailed with the \"Implementation Notes\". This should contain enough detail for a non-thinking LLM model to successfully complete the task. Put these instructions in a collapsible field `<details>`.\n\n   #### Step 2: Dependency Analysis\n   For each task, identify:\n   - **Hard dependencies**: Tasks that MUST complete before this can start\n   - **Soft dependencies**: Tasks that SHOULD complete for optimal execution\n   - **No circular dependencies**: Validate the dependency graph is acyclic\n\n   Dependency Rule: Task B depends on Task A if:\n   - B requires output or artifacts from A\n   - B modifies code created by A\n   - B tests functionality implemented in A\n\n   #### Step 3: Task Generation\n\n   ##### Frontmatter Structure\n\n   Example:\n   ```yaml\n   ---\n   id: 1\n   group: \"user-authentication\"\n   dependencies: []  # List of task IDs, e.g., [2, 3]\n   status: \"pending\"  # pending | in-progress | completed | needs-clarification\n   created: \"2024-01-15\"\n   skills: [\"react-components\", \"authentication\"]  # Technical skills required for this task\n   # Optional: Include complexity scores for high-complexity tasks or decomposition tracking\n   # complexity_score: 4.2  # Composite complexity score (only if >4 or decomposed)\n   # complexity_notes: \"Decomposed from original task due to high technical depth\"\n   ---\n   ```\n\n   The schema for this frontmatter is:\n   ```json\n   {\n     \"type\": \"object\",\n     \"required\": [\"id\", \"group\", \"dependencies\", \"status\", \"created\", \"skills\"],\n     \"properties\": {\n       \"id\": {\n         \"type\": [\"number\"],\n         \"description\": \"Unique identifier for the task. An integer.\"\n       },\n       \"group\": {\n         \"type\": \"string\",\n         \"description\": \"Group or category the task belongs to\"\n       },\n       \"dependencies\": {\n         \"type\": \"array\",\n         \"description\": \"List of task IDs this task depends on\",\n         \"items\": {\n           \"type\": [\"number\"]\n         }\n       },\n       \"status\": {\n         \"type\": \"string\",\n         \"enum\": [\"pending\", \"in-progress\", \"completed\", \"needs-clarification\"],\n         \"description\": \"Current status of the task\"\n       },\n       \"created\": {\n         \"type\": \"string\",\n         \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}$\",\n         \"description\": \"Creation date in YYYY-MM-DD format\"\n       },\n       \"skills\": {\n         \"type\": \"array\",\n         \"description\": \"Technical skills required for this task (1-2 skills recommended)\",\n         \"items\": {\n           \"type\": \"string\",\n           \"pattern\": \"^[a-z][a-z0-9-]*$\"\n         },\n         \"minItems\": 1,\n         \"uniqueItems\": true\n       },\n       \"complexity_score\": {\n         \"type\": \"number\",\n         \"minimum\": 1,\n         \"maximum\": 10,\n         \"description\": \"Optional: Composite complexity score (include only if >4 or for decomposed tasks)\"\n       },\n       \"complexity_notes\": {\n         \"type\": \"string\",\n         \"description\": \"Optional: Rationale for complexity score or decomposition decisions\"\n       }\n     },\n     \"additionalProperties\": false\n   }\n   ```\n\n   ##### Task Body Structure\n\n   Use the task template in .ai/task-manager/config/templates/TASK_TEMPLATE.md\n\n   ##### Task ID Generation\n\n   When creating tasks, you need to determine the next available task ID for the specified plan. Use this bash command to automatically generate the correct ID:\n\n   ```bash\n   node .ai/task-manager/config/scripts/get-next-task-id.cjs {{plan_id}}\n   ```\n\n   ### Validation Checklist\n   Before finalizing, ensure:\n\n   **Core Task Requirements:**\n   - [ ] Each task has 1-2 appropriate technical skills assigned\n   - [ ] Skills are automatically inferred from task objectives and technical requirements\n   - [ ] All dependencies form an acyclic graph\n   - [ ] Task IDs are unique and sequential\n   - [ ] Groups are consistent and meaningful\n   - [ ] Every **explicitly stated** task from the plan is covered\n   - [ ] No redundant or overlapping tasks\n\n   **Complexity Analysis & Controls:**\n   - [ ] **Complexity Analysis Complete**: All tasks assessed using 5-dimension scoring\n   - [ ] **Decomposition Applied**: Tasks with composite score ≥6 have been decomposed or justified\n   - [ ] **Final Task Complexity**: All final tasks have composite score ≤5 (target ≤4)\n   - [ ] **Iteration Limits Respected**: No task exceeded 3 decomposition rounds\n   - [ ] **Minimum Viability**: No tasks decomposed below complexity threshold of 3\n   - [ ] **Quality Gates Passed**: All decomposed tasks meet enhanced quality criteria\n   - [ ] **Dependency Integrity**: No circular dependencies or orphaned tasks exist\n   - [ ] **Error Handling Complete**: All edge cases resolved or escalated appropriately\n\n   **Complexity Documentation Requirements:**\n   - [ ] **Complexity Scores Documented**: Individual dimension scores recorded for complex tasks\n   - [ ] **Decomposition History**: Iteration tracking included in `complexity_notes` for decomposed tasks\n   - [ ] **Validation Status**: All tasks marked with appropriate validation outcomes\n   - [ ] **Escalation Documentation**: High-complexity tasks have clear escalation notes\n   - [ ] **Consistency Validated**: Complexity scores align with task descriptions and skills\n\n   **Scope & Quality Control:**\n   - [ ] **Minimization Applied**: Each task is absolutely necessary (20-30% reduction target)\n   - [ ] **Test Tasks are Meaningful**: Focus on business logic, not framework functionality\n   - [ ] **No Gold-plating**: Only plan requirements are addressed\n   - [ ] **Total Task Count**: Represents minimum viable implementation\n   - [ ] **Scope Preservation**: Decomposed tasks collectively match original requirements\n\n   **System Reliability:**\n   - [ ] **Error Conditions Resolved**: No unresolved error states remain\n   - [ ] **Manual Intervention Flagged**: Complex edge cases properly escalated\n   - [ ] **Quality Checkpoints**: All validation gates completed successfully\n   - [ ] **Dependency Graph Validated**: Full dependency analysis confirms acyclic, logical relationships\n\n   ### Error Handling\n   If the plan lacks sufficient detail:\n   - Note areas needing clarification\n   - Create placeholder tasks marked with `status: \"needs-clarification\"`\n   - Document assumptions made\n\n   #### Step 4: POST_TASK_GENERATION_ALL hook\n\n   Read and run the .ai/task-manager/config/hooks/POST_TASK_GENERATION_ALL.md\n\n   ### Output Requirements\n\n   **Output Behavior:**\n\n   Provide a concise completion message with task count:\n   - Example: \"Tasks generated for plan [id]: [count] tasks created\"\n\n   **CRITICAL - Structured Output for Command Coordination:**\n\n   Always end your output with a standardized summary in this exact format:\n\n   ```\n   ---\n   Task Generation Summary:\n   - Plan ID: [numeric-id]\n   - Tasks: [count]\n   - Status: Ready for execution\n   ```\n\n   This structured output enables automated workflow coordination and must be included even when running standalone.\n\n   ## Resume Blueprint Execution\n\n   After task generation completes, continue with the execution process below.\n\nOtherwise, if tasks exist, proceed directly to execution.\n\n## Execution Process\n\nUse your internal Todo task tool to track the execution of all phases, and the final update of the plan with the summary. Example:\n\n- [ ] Create feature branch from the main branch.\n- [ ] Validate or auto-generate tasks and execution blueprint if missing.\n- [ ] Execute .ai/task-manager/config/hooks/PRE_PHASE.md hook before Phase 1.\n- [ ] Phase 1: Execute 1 task(s) in parallel.\n- [ ] Execute .ai/task-manager/config/hooks/POST_PHASE.md hook after Phase 1.\n- [ ] Execute .ai/task-manager/config/hooks/PRE_PHASE.md hook before Phase 2.\n- [ ] Phase 2: Execute 3 task(s) in parallel.\n- [ ] Execute .ai/task-manager/config/hooks/POST_PHASE.md hook after Phase 2.\n- [ ] Execute .ai/task-manager/config/hooks/PRE_PHASE.md hook before Phase 3.\n- [ ] Phase 3: Execute 1 task(s) in parallel.\n- [ ] Execute .ai/task-manager/config/hooks/POST_PHASE.md hook after Phase 3.\n- [ ] Update the Plan 7 with execution summary using .ai/task-manager/config/hooks/EXECUTION_SUMMARY_TEMPLATE.md.\n- [ ] Archive Plan 7.\n\n### Phase Pre-Execution\n\nRead and execute .ai/task-manager/config/hooks/PRE_PHASE.md\n\n### Phase Execution Workflow\n\n1. **Phase Initialization**\n    - Identify current phase from the execution blueprint\n    - List all tasks scheduled for parallel execution in this phase\n\n2. **Agent Selection and Task Assignment**\nRead and execute .ai/task-manager/config/hooks/PRE_TASK_ASSIGNMENT.md\n\n3. **Parallel Execution**\n    - Deploy all selected agents simultaneously using your internal Task tool\n    - Monitor execution progress for each task\n    - Capture outputs and artifacts from each agent\n    - Update task status in real-time\n\n4. **Phase Completion Verification**\n    - Ensure all tasks in the phase have status: \"completed\"\n    - Collect and review all task outputs\n    - Document any issues or exceptions encountered\n\n### Phase Post-Execution\n\nRead and execute .ai/task-manager/config/hooks/POST_PHASE.md\n\n\n### Phase Transition\n\n  - Update phase status to \"completed\" in the Blueprint section of the plan {{plan_id}} document.\n  - Initialize next phase\n  - Repeat process until all phases are complete\n\n### Error Handling\n\n#### Validation Gate Failures\nRead and execute .ai/task-manager/config/hooks/POST_ERROR_DETECTION.md\n\n### Output Requirements\n\n**Output Behavior:**\n\nProvide a concise execution summary:\n- Example: \"Execution completed. Review summary: `.ai/task-manager/archive/[plan]/plan-[id].md`\"\n\n**CRITICAL - Structured Output for Command Coordination:**\n\nAlways end your output with a standardized summary in this exact format:\n\n```\n---\nExecution Summary:\n- Plan ID: [numeric-id]\n- Status: Archived\n- Location: .ai/task-manager/archive/[plan-id]--[plan-name]/\n```\n\nThis structured output enables automated workflow coordination and must be included even when running standalone.\n\n## Optimization Guidelines\n\n- **Maximize parallelism**: Always run all available tasks in a phase simultaneously\n- **Resource awareness**: Balance agent allocation with system capabilities\n- **Early failure detection**: Monitor tasks actively to catch issues quickly\n- **Continuous improvement**: Note patterns for future blueprint optimization\n\n## Post-Execution Processing\n\nUpon successful completion of all phases and validation gates, perform the following additional steps:\n\n- [ ] Execution Summary Generation\n- [ ] Plan Archival\n\n### 1. Execution Summary Generation\n\nAppend an execution summary section to the plan document with the format described in .ai/task-manager/config/templates/[EXECUTION_SUMMARY_TEMPLATE.md\n\n### 2. Plan Archival\n\nAfter successfully appending the execution summary:\n\n**Move completed plan to archive**:\n```bash\nmv .ai/task-manager/plans/[plan-folder] .ai/task-manager/archive/\n```\n\n### Important Notes\n\n- **Only archive on complete success**: Archive operations should only occur when ALL phases are completed and ALL validation gates have passed\n- **Failed executions remain active**: Plans that fail execution or validation should remain in the `plans/` directory for debugging and potential re-execution\n- **Error handling**: If archival fails, log the error but do not fail the overall execution - the implementation work is complete\n- **Preserve structure**: The entire plan folder (including all tasks and subdirectories) should be moved as-is to maintain referential integrity\n"""
